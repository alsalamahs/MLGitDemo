{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to PyTorch",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alsalamahs/MLGitDemo/blob/master/Introduction_to_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJc-uAekwDVD",
        "colab_type": "text"
      },
      "source": [
        "In this notebook, we will introduce PyTorch, talk about its important concepts and features, and eventually train an MNIST classifier using what we have learned. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXR4A8MKuY5V",
        "colab_type": "text"
      },
      "source": [
        "## NOTE: Click the top-left \"Open In Playground\" button! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKJkpn84iMBw",
        "colab_type": "text"
      },
      "source": [
        "## What is PyTorch?\n",
        "\n",
        "1. A Python GPU-accelerated tensor library (NumPy, but faster)\n",
        "2. Differentiable Programming with dynamic computation graphs\n",
        "3. Flexible and efficient **neural network** library\n",
        "4. Python-first framework (easy to integrate with other Python libraries, debug, and extend)\n",
        "  + Quick conversion from & to NumPy array, integration with other Python libs.\n",
        "  + Your favorite Python debugger.\n",
        "  + Adding custom ops with Python/c++ extension. \n",
        "  + Running in purely c++ environment with the c++ API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCij29tonH84",
        "colab_type": "text"
      },
      "source": [
        "Useful links:\n",
        "\n",
        "+ PyTorch documentation: https://pytorch.org/docs/stable/index.html\n",
        "\n",
        "  Most math operations can be found as `torch.*` or `Tensor.*`.\n",
        "+ PyTorch official tutorials (60-min blitz is a good start): https://pytorch.org/tutorials/\n",
        "    - Transfer learning tutorial: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "+ PyTorch examples (DCGAN, ImageNet training, Reinforcement Learning, etc.): https://github.com/pytorch/examples/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgmnwpcHf8U0",
        "colab_type": "code",
        "outputId": "6dc29d98-0fb3-47fc-ab6e-a0f31302516a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# install basical image libs\n",
        "!pip install Pillow>=5.0.0\n",
        "!pip install -U image\n",
        "\n",
        "# install torch and torchvision (a utility library for computer vision that provides many public datasets and pre-trained models)\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.1.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n",
            "Requirement already satisfied, skipping upgrade: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.3.0)\n",
            "Requirement already satisfied, skipping upgrade: django in /usr/local/lib/python3.6/dist-packages (from image) (2.2.3)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n",
            "Requirement already satisfied, skipping upgrade: sqlparse in /usr/local/lib/python3.6/dist-packages (from django->image) (0.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj3oX5WEkM8P",
        "colab_type": "text"
      },
      "source": [
        "## GPU-accelerated Tensor Library\n",
        "\n",
        "A Tensor is a multi-dimensional array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPdEDFjyf94_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cVfJH3PgvCE",
        "colab_type": "code",
        "outputId": "2394f013-466d-464f-ed7e-e22376a4182a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Create a 3x5 matrix filled with zeros\n",
        "\n",
        "x = torch.zeros(3, 5)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qauqxYzmgQBO",
        "colab_type": "code",
        "outputId": "8bcd4792-be9d-434e-b491-d5f849389ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Create a 3x5 matrix filled with random values\n",
        "\n",
        "y = torch.randn(3, 5)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.8744,  0.9280, -0.6588, -0.3902,  0.5511],\n",
            "        [ 0.0770, -1.0809, -1.3102,  1.7989,  0.6384],\n",
            "        [ 0.3242, -0.0301,  1.6886, -0.5148,  0.3431]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUS9LmmF58gI",
        "colab_type": "code",
        "outputId": "25a33843-1776-4837-9702-ab9165b13b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "# Shape manipulations\n",
        "\n",
        "print('\\n.t()  (transpose): ')\n",
        "print(y.t())\n",
        "\n",
        "print('.reshape(5, 3): ')\n",
        "print(y.reshape(5, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ".t()  (transpose): \n",
            "tensor([[-0.8744,  0.0770,  0.3242],\n",
            "        [ 0.9280, -1.0809, -0.0301],\n",
            "        [-0.6588, -1.3102,  1.6886],\n",
            "        [-0.3902,  1.7989, -0.5148],\n",
            "        [ 0.5511,  0.6384,  0.3431]])\n",
            ".reshape(5, 3): \n",
            "tensor([[-0.8744,  0.9280, -0.6588],\n",
            "        [-0.3902,  0.5511,  0.0770],\n",
            "        [-1.0809, -1.3102,  1.7989],\n",
            "        [ 0.6384,  0.3242, -0.0301],\n",
            "        [ 1.6886, -0.5148,  0.3431]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-qEF8if6VkQ",
        "colab_type": "code",
        "outputId": "45535c8d-2167-4b8a-9370-9e9569886fda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Slicing\n",
        "\n",
        "print(y[1:])\n",
        "\n",
        "print(y[1:, ::2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0770, -1.0809, -1.3102,  1.7989,  0.6384],\n",
            "        [ 0.3242, -0.0301,  1.6886, -0.5148,  0.3431]])\n",
            "tensor([[ 0.0770, -1.3102,  0.6384],\n",
            "        [ 0.3242,  1.6886,  0.3431]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGpFKCBEgbJe",
        "colab_type": "code",
        "outputId": "d083058b-c39c-40fb-b819-12f594c173ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Basic arithmetics\n",
        "\n",
        "print(x + 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2., 2., 2., 2.],\n",
            "        [2., 2., 2., 2., 2.],\n",
            "        [2., 2., 2., 2., 2.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvoZaG8NkbHx",
        "colab_type": "code",
        "outputId": "395a5d84-2e46-428a-eb73-7e48d3414333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(y * (x + 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.7487,  1.8560, -1.3176, -0.7803,  1.1022],\n",
            "        [ 0.1540, -2.1619, -2.6204,  3.5978,  1.2768],\n",
            "        [ 0.6484, -0.0602,  3.3772, -1.0297,  0.6862]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zktd6b7wkgF2",
        "colab_type": "code",
        "outputId": "08d65cf0-45cf-48b3-d1b0-ac6dd54b8a0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print((y * (x + 2)).exp())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.1740,  6.3982,  0.2678,  0.4583,  3.0107],\n",
            "        [ 1.1665,  0.1151,  0.0728, 36.5182,  3.5853],\n",
            "        [ 1.9125,  0.9416, 29.2876,  0.3571,  1.9861]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2dhiDLzkyQF",
        "colab_type": "text"
      },
      "source": [
        "#### GPU Acceleration\n",
        "\n",
        "Everything can be run on a GPU\n",
        "\n",
        "First, let us create a [`torch.device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch-device) object representing a GPU device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPdqlb1CkmqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cuda0 = torch.device('cuda:0')  # pick the GPU at index 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTUbNmkAVr-a",
        "colab_type": "code",
        "outputId": "c4452a2b-79d3-4b7f-9881-27178bbc955c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8744,  0.9280, -0.6588, -0.3902,  0.5511],\n",
              "        [ 0.0770, -1.0809, -1.3102,  1.7989,  0.6384],\n",
              "        [ 0.3242, -0.0301,  1.6886, -0.5148,  0.3431]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCYhVhc-lE7N",
        "colab_type": "code",
        "outputId": "99e0fc75-62b7-4456-ec27-05c351f30a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Move a tensor from CPU to GPU\n",
        "# NOTE: the first time you access a GPU, a context is created so this may take a\n",
        "# few seconds. But subsequent uses will be fast.\n",
        "\n",
        "cuda_y = y.to(cuda0)\n",
        "print(cuda_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.8744,  0.9280, -0.6588, -0.3902,  0.5511],\n",
            "        [ 0.0770, -1.0809, -1.3102,  1.7989,  0.6384],\n",
            "        [ 0.3242, -0.0301,  1.6886, -0.5148,  0.3431]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhhaWnPvlQ0F",
        "colab_type": "code",
        "outputId": "ae2c5160-e816-48b5-b6c1-acae8660c43f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Or directly creating a tensor on GPU\n",
        "\n",
        "cuda_x = torch.zeros(3, 5, device=cuda0)\n",
        "print(cuda_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnaL5mNimjXo",
        "colab_type": "code",
        "outputId": "215a1d87-a487-4e69-e963-66fc5e1ff9e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# All functions and methods work on GPU tensors\n",
        "\n",
        "print((cuda_y * (cuda_x + 2)).exp())  # values match the CPU results above!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.1740,  6.3982,  0.2678,  0.4583,  3.0107],\n",
            "        [ 1.1665,  0.1151,  0.0728, 36.5182,  3.5853],\n",
            "        [ 1.9125,  0.9416, 29.2876,  0.3571,  1.9861]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJb9shauw6Bu",
        "colab_type": "text"
      },
      "source": [
        "### NumPy Bridge\n",
        "\n",
        "Converting a `torch.Tensor` to a `np.ndarray` and vice versa is a breeze.\n",
        "\n",
        "The `torch.Tensor` and `np.ndarray` will share their underlying memory locations (if the `torch.Tensor` is on CPU and `dtype` is the same), and changing one will change the other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjPmAYWIxeM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHPeZwjPWwlx",
        "colab_type": "code",
        "outputId": "08ea4058-720b-4a01-8cfc-e9261d6c02af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "x = torch.randn(5)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.8433, -0.4097, -1.6601,  0.3581, -0.5345])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1zJ0SnrW0En",
        "colab_type": "code",
        "outputId": "9aa713ac-3081-407c-aa7b-bf415a11a87d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "x.numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.8432796 , -0.40973672, -1.6601192 ,  0.3580714 , -0.5344998 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho41TWYcw5xt",
        "colab_type": "code",
        "outputId": "87310822-5009-4341-f75b-e9f9c4b4196e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Converting a tensor to an array\n",
        "\n",
        "x = torch.randn(5)\n",
        "print(x)\n",
        "\n",
        "# use `my_tensor.numpy()`\n",
        "x_np = x.numpy()\n",
        "print(x_np)\n",
        "\n",
        "# or `np.asarray`\n",
        "\n",
        "x_np = np.asarray(x)\n",
        "print(x_np)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.7391, -0.7181, -3.2596,  2.2210,  1.0768])\n",
            "[ 0.73911566 -0.7181137  -3.259646    2.221019    1.0767806 ]\n",
            "[ 0.73911566 -0.7181137  -3.259646    2.221019    1.0767806 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqS8il2AxrAB",
        "colab_type": "code",
        "outputId": "57fbdeac-ef97-44c5-db60-03aa615826e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# in-place changes on one affects the other\n",
        "\n",
        "x[0] = -1\n",
        "print(x)\n",
        "print(x_np)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.0000, -0.7181, -3.2596,  2.2210,  1.0768])\n",
            "[-1.        -0.7181137 -3.259646   2.221019   1.0767806]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfVwkxI8x5ks",
        "colab_type": "code",
        "outputId": "0ce114e7-a20b-406f-a699-8be919ee7e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Converting an array to a tensor\n",
        "\n",
        "a = np.random.randn(3, 4)\n",
        "\n",
        "a_pt = torch.as_tensor(a)\n",
        "print(a_pt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.6790, -0.1510, -0.8305,  1.2007],\n",
            "        [ 0.0102, -0.0697, -0.4782, -1.3210],\n",
            "        [-0.7971,  1.2852,  0.4573,  1.2090]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RmnP6Sayb19",
        "colab_type": "code",
        "outputId": "50fad562-13a5-4fd7-9680-38e47b12699b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# the resulting CPU Tensor shares memory with the array!\n",
        "\n",
        "a_pt[0] = -1\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.         -1.         -1.         -1.        ]\n",
            " [ 0.01015544 -0.06972739 -0.47822052 -1.32100022]\n",
            " [-0.79705154  1.28522745  0.45733386  1.20901938]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaT4EeJ0yaGh",
        "colab_type": "code",
        "outputId": "b839ed6b-de7f-4b7e-855c-8c1f273d1be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# But if we change dtype and/or device at the same time, a copy is made\n",
        "\n",
        "a_half_pt = torch.as_tensor(a, dtype=torch.float16, device=cuda0)\n",
        "a_half_pt[0] = 9\n",
        "print(a_half_pt)\n",
        "\n",
        "print(a)  # original array is not affected"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 9.0000,  9.0000,  9.0000,  9.0000],\n",
            "        [ 0.0102, -0.0697, -0.4783, -1.3213],\n",
            "        [-0.7969,  1.2852,  0.4573,  1.2090]], device='cuda:0',\n",
            "       dtype=torch.float16)\n",
            "[[-1.         -1.         -1.         -1.        ]\n",
            " [ 0.01015544 -0.06972739 -0.47822052 -1.32100022]\n",
            " [-0.79705154  1.28522745  0.45733386  1.20901938]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z6UZea7mzza",
        "colab_type": "text"
      },
      "source": [
        "## Differentiable Programming with Dynamic Computation Graphs\n",
        "\n",
        "Gradient-based optimization is an essential part of the modern deep learning frenzy. PyTorch uses [reverse-mode automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) to efficiently compute gradients through any computations done on tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3M1k2eVJTHy",
        "colab_type": "text"
      },
      "source": [
        "### Dynamic vs. Static\n",
        "\n",
        "A neural network is essentially a sequence of mathematical operations on tensors, which build up a computation graph.\n",
        "\n",
        "Most frameworks such as TensorFlow, Theano, Caffe and CNTK have a static view of the world. One has to build a neural network, and reuse the same structure again and again. Changing the way the network behaves means that one has to start from scratch.\n",
        "\n",
        "PyTorch uses a technique called reverse-mode auto-differentiation, which allows you to change the way your network behaves arbitrarily with zero lag or overhead. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GEfWbBdJVAP",
        "colab_type": "text"
      },
      "source": [
        "### Dynamic computation graphs\n",
        "\n",
        "When you create a tensor with its `requires_grad` flag set to `True`, the [`autograd`](https://pytorch.org/docs/stable/autograd.html) engine considers it as a **leaf** node of the computation graph. As you compute with it, the graph is dynamically expanded. When you ask for gradients (e.g., via `tensor.backward()`), the `autograd` engine traces backwards through the graph, and automatically computes the gradients for you.\n",
        "\n",
        "![alt text](https://github.com/pytorch/pytorch/raw/master/docs/source/_static/img/dynamic_graph.gif)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9oa0qkCJX3T",
        "colab_type": "text"
      },
      "source": [
        "**Let's see this in action!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktc74vsEmq-J",
        "colab_type": "code",
        "outputId": "f59d1bf3-1c71-4fb2-af51-5422bb1b27d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Now, we want tensors with `requires_grad=True`\n",
        "\n",
        "a = torch.ones(3, 5, requires_grad=True)  # tensor of all ones\n",
        "print(a)  # notice that the `requires_grad` flag is on!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz3hpPdnrD4v",
        "colab_type": "code",
        "outputId": "3cfc1a84-d084-4011-e6ed-d24bdef951e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Currently `a` has no gradients\n",
        "\n",
        "print(a.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muZKbhGWqLAi",
        "colab_type": "code",
        "outputId": "3666f1e9-31ef-439c-a0a5-884b4ffe6c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Let's compute the gradient wrt the sum\n",
        "\n",
        "s = a.sum()\n",
        "print('sum of a is', s)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sum of a is tensor(15., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N5WmWHpqe_z",
        "colab_type": "code",
        "outputId": "1737b7bf-3ba4-4dc0-e745-5a1ae316ea74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Notice the `grad_fn` of `s`. it represents the function used to propagate \n",
        "# gradients from `s` to previous nodes of the graph (`a` in this case).\n",
        "\n",
        "s.backward()  # compute gradient!\n",
        "print(a.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-09eMIzrAvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Yay! Indeed d \\sum_a / d a_ij = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yZUx9OvrPNd",
        "colab_type": "code",
        "outputId": "5b7d861a-4e21-4de7-950f-1819d99d3a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Gradients are automatically **accumulated**\n",
        "\n",
        "a.sum().backward()\n",
        "print(a.grad)  # now the new gradients are added to the old ones\n",
        "\n",
        "# Don't worry, we have easy ways to clear the gradients too. \n",
        "# We will talk about those later!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2., 2., 2., 2.],\n",
            "        [2., 2., 2., 2., 2.],\n",
            "        [2., 2., 2., 2., 2.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFVA1MV2rapV",
        "colab_type": "code",
        "outputId": "72500b41-677f-45fc-e2ce-808788821426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Now let's do something slightly fancier, on GPU!\n",
        "\n",
        "a = torch.ones(3, 4, device=cuda0, requires_grad=True)\n",
        "b = torch.randn(4, 4, device=cuda0, requires_grad=True)\n",
        "\n",
        "result = (torch.mm(a, b.t().exp()) * 0.5).rfft(2).sum() * b.prod() - b.mean()\n",
        "print('this complicated chain of operation gives....')\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this complicated chain of operation gives....\n",
            "tensor(-0.4008, device='cuda:0', grad_fn=<SubBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jP56tn-fQyp",
        "colab_type": "code",
        "outputId": "5b959296-012e-4e1f-cc13-6ee99e3b013a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "result.backward()\n",
        "print('\\ngradient wrt a is')\n",
        "print(a.grad)\n",
        "print('\\ngradient wrt b is')\n",
        "print(b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "gradient wrt a is\n",
            "tensor([[-0.0022, -0.0021, -0.0002,  0.0006],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000]], device='cuda:0')\n",
            "\n",
            "gradient wrt b is\n",
            "tensor([[-0.0567, -0.0698, -0.0825, -0.0595],\n",
            "        [-0.0319, -0.0519, -0.0639, -0.0631],\n",
            "        [-0.0670, -0.0666, -0.0580, -0.0705],\n",
            "        [-0.0661, -0.1020, -0.0744, -0.0738]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IiMxcCYMApV",
        "colab_type": "code",
        "outputId": "9e0a9506-6f14-408f-e611-8c6dc76db726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "########################\n",
        "#                      #\n",
        "#       Exercise       #\n",
        "#                      #\n",
        "########################\n",
        "\n",
        "\n",
        "a = torch.linspace(-3, 3, 10, dtype=torch.float32, requires_grad=True)\n",
        "b = torch.logspace(0.2, 2, 10, requires_grad=True)\n",
        "\n",
        "\n",
        "z = torch.log( b.sum() / a.exp().sum()) - b.sum()\n",
        "print(z)\n",
        "\n",
        "z.backward()\n",
        "\n",
        "print(a.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-266.3888, grad_fn=<SubBackward0>)\n",
            "tensor([-0.0012, -0.0024, -0.0046, -0.0089, -0.0174, -0.0339, -0.0659, -0.1284,\n",
            "        -0.2501, -0.4872])\n",
            "tensor([-0.9963, -0.9963, -0.9963, -0.9963, -0.9963, -0.9963, -0.9963, -0.9963,\n",
            "        -0.9963, -0.9963])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGlmZlR-NNld",
        "colab_type": "text"
      },
      "source": [
        "Compute \n",
        "\n",
        "$$z = \\log \\left( \\frac{1}{\\sum_i \\exp(a_i)} \\sum_j b_j \\right) - \\sum_k b_k,$$\n",
        "\n",
        "and then the gradients of $z$ w.r.t. $\\mathbf{a}$ and $\\mathbf{b}$.\n",
        "\n",
        "They should look like:\n",
        "\n",
        "```\n",
        "# Gradient wrt a\n",
        "tensor([-0.0012, -0.0024, -0.0046, -0.0089, -0.0174, -0.0339, -0.0659, -0.1284,\n",
        "        -0.2501, -0.4872])\n",
        "\n",
        "# Gradient wrt b\n",
        "tensor([-0.9963, -0.9963, -0.9963, -0.9963, -0.9963, -0.9963, -0.9963, -0.9963,\n",
        "        -0.9963, -0.9963])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFNxvwP5u_bs",
        "colab_type": "text"
      },
      "source": [
        "#### Manipulating the `requires_grad` flag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKw8g1TNu5-t",
        "colab_type": "code",
        "outputId": "b819af56-84c1-4804-822b-c37e41cff588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Other than directly setting it at creation time, you can change this flag \n",
        "# in-place using `my_tensor.requires_grad_()`, or, as in the above example, or\n",
        "# just directly setting the attribute.\n",
        "\n",
        "x = torch.randn(1, 4, 5)\n",
        "print(x)\n",
        "print('x does not track gradients')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.3404,  1.2348, -0.4726,  1.8338,  0.9665],\n",
            "         [-0.4777,  2.3249, -0.2659,  0.8649, -0.9776],\n",
            "         [-1.0396, -2.4354,  0.7180, -0.9280, -0.7578],\n",
            "         [-0.6382, -1.4439,  0.2138, -0.6615, -1.5771]]])\n",
            "x does not track gradients\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJThUKldvPFN",
        "colab_type": "code",
        "outputId": "967856f6-678f-4156-baa4-770ed79f28f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "x.requires_grad_()\n",
        "print(x)\n",
        "print('x now **does** track gradients')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.3404,  1.2348, -0.4726,  1.8338,  0.9665],\n",
            "         [-0.4777,  2.3249, -0.2659,  0.8649, -0.9776],\n",
            "         [-1.0396, -2.4354,  0.7180, -0.9280, -0.7578],\n",
            "         [-0.6382, -1.4439,  0.2138, -0.6615, -1.5771]]], requires_grad=True)\n",
            "x now **does** track gradients\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAvixGtnv459",
        "colab_type": "text"
      },
      "source": [
        "## Flexible and Efficient Neural Network Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni-h3bBGz0kf",
        "colab_type": "text"
      },
      "source": [
        "The [`torch.nn`](https://pytorch.org/docs/stable/nn.html) and [`torch.optim`](https://pytorch.org/docs/stable/optim.html) packages provide many efficient implementations of neural network components:\n",
        "  + Affine layers and [activation functions](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
        "  + Normalization methods\n",
        "  + [Initialization schemes](https://pytorch.org/docs/stable/nn.html#torch-nn-init)\n",
        "  + [Loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
        "  + [Embeddings](https://pytorch.org/docs/stable/nn.html#sparse-layers)\n",
        "  + [Distributed and Multi-GPU training](https://pytorch.org/docs/stable/nn.html#dataparallel-layers-multi-gpu-distributed)\n",
        "  + [Gradient-based optimizers](https://pytorch.org/docs/stable/optim.html)\n",
        "  + [Learning rate schedulers](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate)\n",
        "  + etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XWfNgtI0NE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyMj2K002oz8",
        "colab_type": "text"
      },
      "source": [
        "#### `torch.nn` Layers\n",
        "\n",
        "We will use the [fully connected linear layer (`nn.Linear`)](https://pytorch.org/docs/stable/nn.html#torch.nn.Linear) as an example. \n",
        "\n",
        "A fc layer performs an affine transform with a 2D weight parameter $\\mathbf{w}$ and a 1D bias parameter $\\mathbf{b}$:\n",
        "\n",
        "$$ f(\\mathbf{x}) = \\mathbf{w}^\\mathrm{T} \\mathbf{x} + \\mathbf{b}.$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpkSxb3UvZYF",
        "colab_type": "code",
        "outputId": "aa4caa48-89c1-43f1-be17-ee986960766a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "fc = nn.Linear(in_features=8, out_features=8)\n",
        "print(fc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=8, out_features=8, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRYaIS5vzyoF",
        "colab_type": "code",
        "outputId": "b5455a51-42f1-4324-9d2e-499d2f6067d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# It has two parameters, the weight and the bias\n",
        "\n",
        "for name, p in fc.named_parameters():\n",
        "    print('param name: {}\\t shape: {}'.format(name, p.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "param name: weight\t shape: torch.Size([8, 8])\n",
            "param name: bias\t shape: torch.Size([8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKNxg_ggfaCN",
        "colab_type": "code",
        "outputId": "88a1f237-e79b-4c2c-e524-e65e052b5ce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "fc.weight"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.2669,  0.1907, -0.1391, -0.3276,  0.1498,  0.3402,  0.3010, -0.2500],\n",
              "        [ 0.0154,  0.3147, -0.2032, -0.2937, -0.2662,  0.0713,  0.0804,  0.0981],\n",
              "        [ 0.0988,  0.0569,  0.1203,  0.2472,  0.0577, -0.0078, -0.1302,  0.0956],\n",
              "        [-0.0064,  0.1049, -0.2925, -0.0192, -0.3011, -0.2878, -0.1191, -0.3001],\n",
              "        [ 0.1697,  0.3415,  0.1356, -0.0279,  0.3087,  0.2876,  0.1874, -0.2123],\n",
              "        [-0.1191,  0.2579,  0.2103, -0.1575, -0.2197,  0.1573, -0.3480,  0.0270],\n",
              "        [-0.0302,  0.2779,  0.1500,  0.2312,  0.0566, -0.1994, -0.0517,  0.2655],\n",
              "        [-0.1173,  0.2121,  0.0729,  0.0713, -0.2098, -0.0373, -0.0443,  0.0630]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgGxaH8P0k6d",
        "colab_type": "code",
        "outputId": "492345ee-c1ec-497e-a3ce-e69076086f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# These parameters by default have `requires_grad=True`, so they will collect gradients!\n",
        "\n",
        "print(fc.bias)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([ 0.3485,  0.3280, -0.3456, -0.0870, -0.2239, -0.0148, -0.2640,  0.1459],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21nZqKk009u2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's construct an input tensor with 2 dimensions:\n",
        "#   - batch dimension of size 64\n",
        "#   - 8 features\n",
        "\n",
        "x = torch.randn(64, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR0uDfsI1Ybq",
        "colab_type": "code",
        "outputId": "36b9e8a6-7a91-43a2-93c9-af0600d30eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Pass it through the fc layer\n",
        "\n",
        "result = fc(x)\n",
        "print(result.shape)\n",
        "\n",
        "# Why does the `result` have shape [64, 8]?\n",
        "#   - batch dimension of size 64\n",
        "#   - 8 output features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKyBTXGE1sQf",
        "colab_type": "code",
        "outputId": "a69f2259-0bfb-45f1-f5a8-aa6ececfeb87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Even though the input `x` has `requires_grad=False`, the convolution\n",
        "# weight and bias parameters has `requires_grad=True`. So the result also\n",
        "# requires gradient, with a `grad_fn` to compute backward pass for \n",
        "# convolutions.\n",
        "print(result.requires_grad)\n",
        "print(result.grad_fn)  # It says `AddmmBackward` because the fc layer performs a matmul and an addition"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "<AddmmBackward object at 0x7f63674ed1d0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_o_34C-4wdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Say (arbitrarily) we want the layer to behave like the cosine function (yes I know it is impossible)\n",
        "\n",
        "target = x.cos()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBh0R7zV7TZK",
        "colab_type": "code",
        "outputId": "39d93c8e-3531-439a-c493-ba845340a5ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Let's try MSE loss\n",
        "\n",
        "loss = F.mse_loss(result, target)\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.0003, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HBUX4To7Zie",
        "colab_type": "code",
        "outputId": "bf366edb-845f-4a82-931b-472efcbcb816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Compute gradients\n",
        "\n",
        "loss.backward()\n",
        "print(fc.bias.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.0578, -0.0557, -0.2481, -0.2105, -0.1780, -0.1764, -0.1997, -0.1282])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RXQNbrf7jy9",
        "colab_type": "code",
        "outputId": "7afa138a-ffa0-4a72-c970-7f6e396fded7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# We can manually perform GD via a loop\n",
        "\n",
        "print('bias before GD', fc.bias)\n",
        "\n",
        "lr = 0.5\n",
        "with torch.no_grad():  \n",
        "    # this context manager tells PyTorch that we don't want ops inside to be \n",
        "    # tracked by autograd!\n",
        "    for p in fc.parameters():\n",
        "        p -= lr * p.grad\n",
        "        \n",
        "print('bias after GD', fc.bias)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bias before GD Parameter containing:\n",
            "tensor([ 0.3485,  0.3280, -0.3456, -0.0870, -0.2239, -0.0148, -0.2640,  0.1459],\n",
            "       requires_grad=True)\n",
            "bias after GD Parameter containing:\n",
            "tensor([ 0.3774,  0.3558, -0.2216,  0.0182, -0.1349,  0.0734, -0.1642,  0.2101],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZq4QtJ8F5v4",
        "colab_type": "text"
      },
      "source": [
        "#### `torch.optim` optimizers\n",
        "\n",
        "More easily, we can use the provided [`torch.optim`](https://pytorch.org/docs/stable/optim.html#torch.optim) optimizers. Let's use the [`torch.optim.SGD`](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD) optimizer for example!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izmy6Kr3HWEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's optimize for 5000 iterations\n",
        "\n",
        "# First, put the layer on GPU so things run faster\n",
        "\n",
        "fc = fc.to(cuda0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iifUdPqu8E-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construct an optimizer\n",
        "\n",
        "optim = torch.optim.SGD(fc.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZoO55hiHMrV",
        "colab_type": "code",
        "outputId": "e0261834-aa93-49fb-b054-443ddb5e15e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# training loop\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "for ii in range(5000):\n",
        "    # clear gradients accumulated on the parameters\n",
        "    optim.zero_grad()\n",
        "    \n",
        "    # get an input (say we only care inputs sampled from N(0, I))\n",
        "    x = torch.randn(batch_size, 8, device=cuda0)  # this has to be on GPU too\n",
        "    \n",
        "    # target is the cos(x)\n",
        "    target = x.cos()\n",
        "    \n",
        "    # forward pass\n",
        "    result = fc(x)\n",
        "    \n",
        "    # compute loss\n",
        "    loss = F.mse_loss(result, target)\n",
        "    \n",
        "    # compute gradients\n",
        "    loss.backward()\n",
        "    \n",
        "    # let the optimizer do its work; the parameters will be updated in this call\n",
        "    optim.step()\n",
        "    \n",
        "    # add some printing\n",
        "    if ii % 500 == 0:\n",
        "        print('iteration {}\\tloss {:.5f}'.format(ii, loss))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0\tloss 0.77930\n",
            "iteration 500\tloss 0.19448\n",
            "iteration 1000\tloss 0.20639\n",
            "iteration 1500\tloss 0.18550\n",
            "iteration 2000\tloss 0.17982\n",
            "iteration 2500\tloss 0.18540\n",
            "iteration 3000\tloss 0.18934\n",
            "iteration 3500\tloss 0.18994\n",
            "iteration 4000\tloss 0.20697\n",
            "iteration 4500\tloss 0.18157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQGaMCr8Isrg",
        "colab_type": "text"
      },
      "source": [
        "### Building Deep Neural Neworks\n",
        "\n",
        "A single `nn.Linear` layer didn't do very well! The MSE loss above is still pretty large.\n",
        "\n",
        "But this is expected as it is simply a linear transformation and thus has limited expressive power. Let's replace it with a deep network and see out it works!\n",
        "\n",
        "For simplicity, we will use the following feedforward network architecture (from top to bottom):\n",
        "\n",
        "```\n",
        "        [Input]\n",
        "           ||\n",
        "[Fully-Connected 8 -> 32]\n",
        "           ||\n",
        "    [ReLU activation]\n",
        "           ||\n",
        "[Fully-Connected 32 -> 32]\n",
        "           ||\n",
        "    [ReLU activation]\n",
        "           ||\n",
        "[Fully-Connected 32 -> 8]\n",
        "           ||\n",
        "        [Output]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVzkaIlsLYJT",
        "colab_type": "text"
      },
      "source": [
        "In PyTorch, a model is represented by a [`nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) object. The `nn.Linear` layer we looked at above is also an instance of it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsJ7nLvAHfyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert isinstance(nn.Linear(8, 8), nn.Module)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jztyotM2Lut9",
        "colab_type": "text"
      },
      "source": [
        "Now we want to build a deep network, we can compose the needed layers together by writing a custom `nn.Module` ourselves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny8gXGpfLpNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyNet(nn.Module):  # subclass nn.Module\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "        \n",
        "        # We need 3 fully-connected layers!\n",
        "        # Simply assigning them as attributes will\n",
        "        # make sure that PyTorch keeps track of them.\n",
        "        \n",
        "        # 8 => 32\n",
        "        self.fc1 = nn.Linear(8, 32)\n",
        "        # 32 => 32\n",
        "        self.fc2 = nn.Linear(32, 32)\n",
        "        # 32 => 8\n",
        "        self.fc3 = nn.Linear(32, 8)\n",
        "        \n",
        "        \n",
        "    # We also need to define a `forward()` method that details\n",
        "    # what should happen when this module is used.\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = x.relu()\n",
        "        x = self.fc2(x)\n",
        "        x = x.relu()\n",
        "        return self.fc3(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuZM4_jeMqsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Okay! Now we are ready to use this deep network! \n",
        "\n",
        "# Construct a network and move to GPU\n",
        "net = MyNet().to(cuda0)\n",
        "\n",
        "# Construct an optimizer\n",
        "optim = torch.optim.SGD(net.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVt8N16MMtxZ",
        "colab_type": "code",
        "outputId": "c9e7ad31-3d0f-4604-9bae-3fff8d3031e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# The same training loop, but now using a deep network!\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "for ii in range(5000):\n",
        "    # clear gradients accumulated on the parameters\n",
        "    optim.zero_grad()\n",
        "    \n",
        "    # get an input (say we only care inputs sampled from N(0, I))\n",
        "    x = torch.randn(batch_size, 8, device=cuda0)  # this has to be on GPU too\n",
        "    \n",
        "    # target is the cos(x)\n",
        "    target = x.cos()\n",
        "    \n",
        "    # forward pass\n",
        "    result = net(x)  # CHANGED: fc => net\n",
        "    \n",
        "    # compute loss\n",
        "    loss = F.mse_loss(result, target)\n",
        "    \n",
        "    # compute gradients\n",
        "    loss.backward()\n",
        "    \n",
        "    # let the optimizer do its work; the parameters will be updated in this call\n",
        "    optim.step()\n",
        "    \n",
        "    # add some printing\n",
        "    if ii % 500 == 0:\n",
        "        print('iteration {}\\tloss {:.5f}'.format(ii, loss))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0\tloss 0.53365\n",
            "iteration 500\tloss 0.16464\n",
            "iteration 1000\tloss 0.08549\n",
            "iteration 1500\tloss 0.03594\n",
            "iteration 2000\tloss 0.01866\n",
            "iteration 2500\tloss 0.01365\n",
            "iteration 3000\tloss 0.01166\n",
            "iteration 3500\tloss 0.00987\n",
            "iteration 4000\tloss 0.00879\n",
            "iteration 4500\tloss 0.00892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsdcbnOQPbhL",
        "colab_type": "text"
      },
      "source": [
        "The network did so much better than a single fully-connected layer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggjwhxk_afWf",
        "colab_type": "text"
      },
      "source": [
        "#### More `nn.*` Layers\n",
        "\n",
        "There are many other layers provided in the `nn.*` package. To list a few, we have\n",
        "+ Convolutions: e.g., [`nn.Conv2d`](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d)\n",
        "+ Normalizations: e.g., [`nn.BatchNorm2d`](https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm2d)\n",
        "+ Activation functions: e.g., [`nn.ReLU`](https://pytorch.org/docs/stable/nn.html#torch.nn.ReLU)\n",
        "+ etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE2k_yV6cp6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A conv 2d layer with 4x4 filters, mapping inputs with 3 channels to outputs with 5 channels\n",
        "\n",
        "conv = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvCPf3wCdTCc",
        "colab_type": "code",
        "outputId": "d66de3ae-c7b4-41d4-d5eb-9cf87e890072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# It also has two parameters, the weight and the bias\n",
        "\n",
        "for name, p in conv.named_parameters():\n",
        "    print('param name: {}\\t shape: {}'.format(name, p.shape))\n",
        "    \n",
        "# Why does the weight have shape [5, 3, 4, 4]? "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "param name: weight\t shape: torch.Size([5, 3, 4, 4])\n",
            "param name: bias\t shape: torch.Size([5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0b8bbC2Yrrx",
        "colab_type": "text"
      },
      "source": [
        "#### `nn.Module` Containers\n",
        "\n",
        "`torch.nn` also provides many other [`nn.Module` containers](https://pytorch.org/docs/stable/nn.html#containers) for easily building complex networks. E.g., [`nn.Sequential`](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential) executes a list of submodules sequentially, passing each output to the next's input. \n",
        "\n",
        "Using `nn.Sequential`, the above network can be equivalently written as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNUcQt93ZY9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = nn.Sequential(\n",
        "    nn.Linear(8, 32),\n",
        "    nn.ReLU(),               # This nn.Module does the ReLU activation on its input\n",
        "    nn.Linear(32, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 8),\n",
        ").to(cuda0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oye4XrPeQR2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################\n",
        "#                      #\n",
        "#       Exercise       #\n",
        "#                      #\n",
        "########################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySx-KPEcQhmL",
        "colab_type": "text"
      },
      "source": [
        "Perform the same regression task (i.e., modeling $f(x) = \\cos(x)$), but with the following modifications:\n",
        "\n",
        "+ Use one *more* hidden layer\n",
        "+ Each hidden layer should have size 128 neurons\n",
        "+ Use the `tanh` activation function (see [`my_tensor.tanh()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.tanh))\n",
        "+ Use a batch size of 128\n",
        "+ Use the [`torch.optim.Adam`](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam) optimizer\n",
        "+ Use the [L1 loss](https://pytorch.org/docs/stable/nn.html#torch.nn.functional.l1_loss) function\n",
        "\n",
        "\n",
        "The following code skeleton is provided. Fill in the places marked with `FIXME!!!`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hzs054WQURe",
        "colab_type": "code",
        "outputId": "8ae28690-f656-472e-9cac-47827c68422c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "class MyDeeperNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyDeeperNet, self).__init__()\n",
        "        \n",
        "        # We need 4 fully-connected layers now! \n",
        "        # Each should have 128 neurons, except for the last one, which outputs vectors of size 8.\n",
        "        \n",
        "        self.fc1 = nn.Linear(8, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 128)\n",
        "        self.fc4 = nn.Linear(128, 8)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = x.tanh()\n",
        "        x = self.fc2(x)\n",
        "        x = x.tanh()\n",
        "        x = self.fc3(x)\n",
        "        x = x.tanh()\n",
        "        return self.fc4(x)\n",
        "        \n",
        "# Construct our new awesome deeper network and move to GPU\n",
        "deeper_net = MyDeeperNet().to(cuda0)\n",
        "\n",
        "# Alternative implementation:\n",
        "#\n",
        "# deeper_net = nn.Sequential(\n",
        "#     nn.Linear(8, 128),\n",
        "#     nn.Tanh(),\n",
        "#     nn.Linear(128, 128),\n",
        "#     nn.Tanh(),\n",
        "#     nn.Linear(128, 128),\n",
        "#     nn.Tanh(),\n",
        "#     nn.Linear(128, 8),\n",
        "# ).to(cuda0)\n",
        "\n",
        "# Construct an Adam optimizer\n",
        "deeper_net_optim = torch.optim.Adam(deeper_net.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "# Training loop\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "for ii in range(5000):\n",
        "    # clear gradients accumulated on the parameters\n",
        "    deeper_net_optim.zero_grad()\n",
        "    \n",
        "    # get an input (say we only care inputs sampled from N(0, I))\n",
        "    x = torch.randn(batch_size, 8, device=cuda0)  # this has to be on GPU too\n",
        "    \n",
        "    # target is the cos(x)\n",
        "    target = x.cos()\n",
        "    \n",
        "    # forward pass\n",
        "    result = deeper_net(x)\n",
        "    \n",
        "    # compute loss\n",
        "    loss = F.l1_loss(result, target)\n",
        "    \n",
        "    # compute gradients\n",
        "    loss.backward()\n",
        "    \n",
        "    # let the optimizer do its work; the parameters will be updated in this call\n",
        "    deeper_net_optim.step()\n",
        "    \n",
        "    # add some printing\n",
        "    if ii % 500 == 0:\n",
        "        print('iteration {}\\tloss {:.5f}'.format(ii, loss))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0\tloss 0.69156\n",
            "iteration 500\tloss 0.06283\n",
            "iteration 1000\tloss 0.04860\n",
            "iteration 1500\tloss 0.03951\n",
            "iteration 2000\tloss 0.04054\n",
            "iteration 2500\tloss 0.04966\n",
            "iteration 3000\tloss 0.03961\n",
            "iteration 3500\tloss 0.04023\n",
            "iteration 4000\tloss 0.04876\n",
            "iteration 4500\tloss 0.04617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyP2LDgkn23L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}